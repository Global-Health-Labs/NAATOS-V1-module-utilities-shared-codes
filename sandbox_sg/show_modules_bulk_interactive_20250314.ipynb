{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAATOS Bulk Analysis Tool for Modules\n",
    "============\n",
    "\n",
    "Simon Ghionea, Started 3/14/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import math\n",
    "import time\n",
    "\n",
    "import plotly.express as px\n",
    "import panel as pn\n",
    "\n",
    "import naatos_module_tools.logreader as logreader\n",
    "import naatos_module_tools.logprocessors as logprocessors\n",
    "import naatos_module_tools.logplotter as logplotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'plotly': 'https://cdn.plot.ly/plotly-2.35.3.min'}, 'shim': {}});\n      require([\"plotly\"], function(Plotly) {\n        window.Plotly = Plotly\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 1;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Plotly !== undefined) && (!(window.Plotly instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.6.0/dist/bundled/plotlyplot/plotly-2.35.3.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.0/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.6.0/dist/bundled/jquery/jquery.min.js\", \"https://cdn.holoviz.org/panel/1.6.0/dist/bundled/plotlyplot/plotly-2.35.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.6.0/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.6.0/dist/bundled/plotlyplot/mapbox-gl-js/v3.0.1/mapbox-gl.css?v=1.6.0\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='bd90715f-be3e-4c6c-a2c6-33f4107a01dc'>\n",
       "  <div id=\"bfa334ee-bd10-4f7e-9c1b-2057dd93935e\" data-root-id=\"bd90715f-be3e-4c6c-a2c6-33f4107a01dc\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"8ffa3350-d2aa-4067-b2d4-82b792041198\":{\"version\":\"3.6.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"bd90715f-be3e-4c6c-a2c6-33f4107a01dc\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"5a043a5e-157b-4c69-a45f-8ca083e9ecc9\",\"attributes\":{\"plot_id\":\"bd90715f-be3e-4c6c-a2c6-33f4107a01dc\",\"comm_id\":\"18b12db15a4d40b0a1fde4ae577ac323\",\"client_comm_id\":\"d44c3a1e3e464309ade3be5cfcfd5f58\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"8ffa3350-d2aa-4067-b2d4-82b792041198\",\"roots\":{\"bd90715f-be3e-4c6c-a2c6-33f4107a01dc\":\"bfa334ee-bd10-4f7e-9c1b-2057dd93935e\"},\"root_ids\":[\"bd90715f-be3e-4c6c-a2c6-33f4107a01dc\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Plotly !== undefined) && ( root.Plotly !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "bd90715f-be3e-4c6c-a2c6-33f4107a01dc"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn.extension(\"plotly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate, Select Experiment Folders, Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found experiment folders: ['20250311_DX_download']\n"
     ]
    }
   ],
   "source": [
    "root = r'C:\\Users\\SimonGhionea\\Global Health Labs, Inc\\NAATOS Product Feasibility - General - Internal - Electronic Control Module\\Beta design\\PowermoduleTestData\\by_exp'\n",
    "#root = r'C:\\Temp\\NAATOS_MODULE_AUTODOWNLOADS'\n",
    "rootpath = Path(root)\n",
    "\n",
    "experiment_list = [x.name for x in rootpath.iterdir() if x.is_dir()];\n",
    "\n",
    "experiments_to_plot = [\n",
    "    #'20250128_sgdev_3.1',\n",
    "    #'20250128_sgdev_3.1_b_abridge_pwmbugsearch',\n",
    "    #'20250128_sgdev_3.1_c_abridge_diffpid',\n",
    "    #'20250128_sgdev_3.1_d_2cycle_emulate',\n",
    "    \n",
    "    #'20250225_sgdev_cooldown_test',\n",
    "    #'20250228_sgdev_cooldown_test',\n",
    "\n",
    "    '20250311_DX_download',\n",
    "    \n",
    "    # '20250310_SimonGhionea_autodl',\n",
    "    # '20250311_SimonGhionea_autodl',\n",
    "    # '20250312_SimonGhionea_autodl',\n",
    "    # '20250313_SimonGhionea_autodl_PM_eelab_continuous',\n",
    "]\n",
    "\n",
    "experiments_to_plot = [x for x in experiments_to_plot if x in experiment_list]\n",
    "\n",
    "print('Found experiment folders:',experiments_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rootfolder C:\\Users\\SimonGhionea\\Global Health Labs, Inc\\NAATOS Product Feasibility - General - Internal - Electronic Control Module\\Beta design\\PowermoduleTestData\\by_exp\n",
      "Experiment 20250311_DX_download\n",
      "The folder we will assume each folder are UNITS\n",
      "folder \"Unit 12\"\n",
      "[]\n",
      "Folder .\n",
      "Done loading log sample_03-06-25_130105.csv\n",
      "Done loading log sample_03-06-25_130105.csv\n",
      "Done loading log sample_03-06-25_133331.csv\n",
      "Done loading log sample_03-06-25_133331.csv\n",
      "Done loading log sample_03-06-25_133432.csv\n",
      "Done loading log sample_03-06-25_133432.csv\n",
      "Done loading log sample_03-06-25_141509.csv\n",
      "Done loading log sample_03-06-25_141509.csv\n",
      "Done loading log sample_03-06-25_145851.csv\n",
      "Done loading log sample_03-06-25_145851.csv\n",
      "Done loading log sample_03-06-25_154038.csv\n",
      "Done loading log sample_03-06-25_154038.csv\n",
      "Done loading log sample_03-06-25_161655.csv\n",
      "Done loading log sample_03-06-25_161655.csv\n",
      "Done loading log sample_03-07-25_115333.csv\n",
      "Done loading log sample_03-07-25_115333.csv\n",
      "Done loading log sample_03-07-25_122408.csv\n",
      "Done loading log sample_03-07-25_122408.csv\n",
      "Done loading log sample_03-07-25_130105.csv\n",
      "Done loading log sample_03-07-25_130105.csv\n",
      "Done loading log sample_03-07-25_135001.csv\n",
      "Done loading log sample_03-07-25_135001.csv\n",
      "Done loading log sample_03-10-25_122300.csv\n",
      "Done loading log sample_03-10-25_122300.csv\n",
      "Done loading log sample_03-10-25_123553.csv\n",
      "Done loading log sample_03-10-25_123553.csv\n",
      "Done loading log sample_03-10-25_132037.csv\n",
      "Done loading log sample_03-10-25_132037.csv\n",
      "Done loading log sample_03-10-25_135621.csv\n",
      "Done loading log sample_03-10-25_135621.csv\n",
      "Done loading log sample_03-10-25_143703.csv\n",
      "Done loading log sample_03-10-25_143703.csv\n",
      "Done loading log sample_03-11-25_112312.csv\n",
      "Done loading log sample_03-11-25_112312.csv\n",
      "Done loading log sample_03-11-25_115951.csv\n",
      "Done loading log sample_03-11-25_115951.csv\n",
      "Done loading log sample_03-11-25_123934.csv\n",
      "Done loading log sample_03-11-25_123934.csv\n",
      "Done loading log sample_03-11-25_131642.csv\n",
      "Done loading log sample_03-11-25_131642.csv\n",
      "Done loading log sample_03-11-25_135257.csv\n",
      "Done loading log sample_03-11-25_135257.csv\n",
      "Done loading log sample_03-11-25_135313.csv\n",
      "Done loading log sample_03-11-25_135313.csv\n",
      "Done loading log sample_03-11-25_144936.csv\n",
      "Done loading log sample_03-11-25_144936.csv\n",
      "folder \"Unit 16\"\n",
      "[]\n",
      "Folder .\n",
      "Done loading log sample_03-06-25_130114.csv\n",
      "Done loading log sample_03-06-25_130114.csv\n",
      "Done loading log sample_03-06-25_135532.csv\n",
      "Done loading log sample_03-06-25_135532.csv\n",
      "Done loading log sample_03-06-25_141517.csv\n",
      "Done loading log sample_03-06-25_141517.csv\n",
      "Done loading log sample_03-06-25_145859.csv\n",
      "Done loading log sample_03-06-25_145859.csv\n",
      "Done loading log sample_03-06-25_154048.csv\n",
      "Done loading log sample_03-06-25_154048.csv\n",
      "Done loading log sample_03-06-25_161704.csv\n",
      "Done loading log sample_03-06-25_161704.csv\n",
      "Done loading log sample_03-06-25_161742.csv\n",
      "Done loading log sample_03-06-25_161742.csv\n",
      "Done loading log sample_03-06-25_162301.csv\n",
      "Done loading log sample_03-06-25_162301.csv\n",
      "Done loading log sample_03-07-25_115342.csv\n",
      "Done loading log sample_03-07-25_115342.csv\n",
      "Done loading log sample_03-07-25_122417.csv\n",
      "Done loading log sample_03-07-25_122417.csv\n",
      "Done loading log sample_03-07-25_130114.csv\n",
      "Done loading log sample_03-07-25_130114.csv\n",
      "Done loading log sample_03-10-25_122312.csv\n",
      "Done loading log sample_03-10-25_122312.csv\n",
      "Done loading log sample_03-10-25_123605.csv\n",
      "Done loading log sample_03-10-25_123605.csv\n",
      "Done loading log sample_03-10-25_132049.csv\n",
      "Done loading log sample_03-10-25_132049.csv\n",
      "Done loading log sample_03-10-25_135633.csv\n",
      "Done loading log sample_03-10-25_135633.csv\n",
      "Done loading log sample_03-11-25_112324.csv\n",
      "Done loading log sample_03-11-25_112324.csv\n",
      "Done loading log sample_03-11-25_120004.csv\n",
      "Done loading log sample_03-11-25_120004.csv\n",
      "Done loading log sample_03-11-25_120054.csv\n",
      "Done loading log sample_03-11-25_120054.csv\n",
      "Done loading log sample_03-11-25_123947.csv\n",
      "Done loading log sample_03-11-25_123947.csv\n",
      "Done loading log sample_03-11-25_131653.csv\n",
      "Done loading log sample_03-11-25_131653.csv\n",
      "Done loading log sample_03-11-25_131756.csv\n",
      "Done loading log sample_03-11-25_131756.csv\n",
      "Done loading log sample_03-11-25_131844.csv\n",
      "Done loading log sample_03-11-25_131844.csv\n",
      "Done loading log sample_03-11-25_132000.csv\n",
      "Done loading log sample_03-11-25_132000.csv\n",
      "Done loading log sample_03-11-25_135308.csv\n",
      "Done loading log sample_03-11-25_135308.csv\n",
      "Done loading log sample_03-11-25_135326.csv\n",
      "Done loading log sample_03-11-25_135326.csv\n",
      "Done loading log sample_03-11-25_142609.csv\n",
      "Done loading log sample_03-11-25_142609.csv\n",
      "Done loading log sample_03-11-25_143511.csv\n",
      "Done loading log sample_03-11-25_143511.csv\n",
      "Done loading log sample_03-11-25_150708.csv\n",
      "Done loading log sample_03-11-25_150708.csv\n",
      "Done loading log sample_03-11-25_151301.csv\n",
      "Done loading log sample_03-11-25_151301.csv\n",
      "folder \"Unit 17\"\n",
      "[]\n",
      "Folder .\n",
      "Done loading log sample_03-06-25_130017.csv\n",
      "Done loading log sample_03-06-25_130017.csv\n",
      "Done loading log sample_03-06-25_133418.csv\n",
      "Done loading log sample_03-06-25_133418.csv\n",
      "Done loading log sample_03-06-25_141500.csv\n",
      "Done loading log sample_03-06-25_141500.csv\n",
      "Done loading log sample_03-06-25_145916.csv\n",
      "Done loading log sample_03-06-25_145916.csv\n",
      "Done loading log sample_03-06-25_154056.csv\n",
      "Done loading log sample_03-06-25_154056.csv\n",
      "Done loading log sample_03-06-25_161721.csv\n",
      "Done loading log sample_03-06-25_161721.csv\n",
      "Done loading log sample_03-07-25_115318.csv\n",
      "Done loading log sample_03-07-25_115318.csv\n",
      "Done loading log sample_03-07-25_122348.csv\n",
      "Done loading log sample_03-07-25_122348.csv\n",
      "Done loading log sample_03-07-25_130058.csv\n",
      "Done loading log sample_03-07-25_130058.csv\n",
      "Done loading log sample_03-07-25_135009.csv\n",
      "Done loading log sample_03-07-25_135009.csv\n",
      "Done loading log sample_03-07-25_150541.csv\n",
      "Done loading log sample_03-07-25_150541.csv\n",
      "Done loading log sample_03-10-25_122415.csv\n",
      "Done loading log sample_03-10-25_122415.csv\n",
      "Done loading log sample_03-10-25_123532.csv\n",
      "Done loading log sample_03-10-25_123532.csv\n",
      "Done loading log sample_03-10-25_132026.csv\n",
      "Done loading log sample_03-10-25_132026.csv\n",
      "Done loading log sample_03-10-25_135640.csv\n",
      "Done loading log sample_03-10-25_135640.csv\n",
      "Done loading log sample_03-10-25_143636.csv\n",
      "Done loading log sample_03-10-25_143636.csv\n",
      "Done loading log sample_03-11-25_112255.csv\n",
      "Done loading log sample_03-11-25_112255.csv\n",
      "Done loading log sample_03-11-25_120010.csv\n",
      "Done loading log sample_03-11-25_120010.csv\n",
      "Done loading log sample_03-11-25_123951.csv\n",
      "Done loading log sample_03-11-25_123951.csv\n",
      "Done loading log sample_03-11-25_131627.csv\n",
      "Done loading log sample_03-11-25_131627.csv\n",
      "Done loading log sample_03-11-25_135342.csv\n",
      "Done loading log sample_03-11-25_135342.csv\n",
      "Done loading log sample_03-11-25_143447.csv\n",
      "Done loading log sample_03-11-25_143447.csv\n",
      "folder \"Unit 30\"\n",
      "[]\n",
      "Folder .\n",
      "Done loading log sample_03-06-25_130001.csv\n",
      "Done loading log sample_03-06-25_130001.csv\n",
      "Done loading log sample_03-06-25_133328.csv\n",
      "Done loading log sample_03-06-25_133328.csv\n",
      "Done loading log sample_03-06-25_141405.csv\n",
      "Done loading log sample_03-06-25_141405.csv\n",
      "Done loading log sample_03-06-25_145746.csv\n",
      "Done loading log sample_03-06-25_145746.csv\n",
      "Done loading log sample_03-06-25_153935.csv\n",
      "Done loading log sample_03-06-25_153935.csv\n",
      "Done loading log sample_03-06-25_161551.csv\n",
      "Done loading log sample_03-06-25_161551.csv\n",
      "Done loading log sample_03-07-25_115229.csv\n",
      "Done loading log sample_03-07-25_115229.csv\n",
      "Done loading log sample_03-07-25_122304.csv\n",
      "Done loading log sample_03-07-25_122304.csv\n",
      "Done loading log sample_03-07-25_130001.csv\n",
      "Done loading log sample_03-07-25_130001.csv\n",
      "Done loading log sample_03-10-25_122204.csv\n",
      "Done loading log sample_03-10-25_122204.csv\n",
      "Done loading log sample_03-10-25_123449.csv\n",
      "Done loading log sample_03-10-25_123449.csv\n",
      "Done loading log sample_03-10-25_131933.csv\n",
      "Done loading log sample_03-10-25_131933.csv\n",
      "file sample_03-10-25_135517.csv had 1 rows with bad times, we will use prior time\n",
      "Done loading log sample_03-10-25_135517.csv\n",
      "Done loading log sample_03-10-25_135517.csv\n",
      "Done loading log sample_03-10-25_143648.csv\n",
      "Done loading log sample_03-10-25_143648.csv\n",
      "Done loading log sample_03-10-25_143657.csv\n",
      "Done loading log sample_03-10-25_143657.csv\n",
      "Done loading log sample_03-11-25_112207.csv\n",
      "Done loading log sample_03-11-25_112207.csv\n",
      "Done loading log sample_03-11-25_115848.csv\n",
      "Done loading log sample_03-11-25_115848.csv\n",
      "Done loading log sample_03-11-25_123831.csv\n",
      "Done loading log sample_03-11-25_123831.csv\n",
      "Done loading log sample_03-11-25_131535.csv\n",
      "Done loading log sample_03-11-25_131535.csv\n",
      "Done loading log sample_03-11-25_135149.csv\n",
      "Done loading log sample_03-11-25_135149.csv\n",
      "Done loading log sample_03-11-25_135209.csv\n",
      "Done loading log sample_03-11-25_135209.csv\n",
      "Done loading log sample_03-11-25_144519.csv\n",
      "Done loading log sample_03-11-25_144519.csv\n",
      "folder \"Unit 32\"\n",
      "[]\n",
      "Folder .\n",
      "Done loading log sample_03-11-25_142451.csv\n",
      "Done loading log sample_03-11-25_142451.csv\n",
      "Done loading log sample_03-11-25_143401.csv\n",
      "Done loading log sample_03-11-25_143401.csv\n",
      "File sample_03-11-25_150556.csv had zero-size! Ignoring\n",
      "Skipped log sample_03-11-25_150556.csv\n",
      "Done loading log sample_03-11-25_150558.csv\n",
      "Done loading log sample_03-11-25_150558.csv\n",
      "folder \"Unit 33\"\n",
      "[]\n",
      "Folder .\n",
      "Done loading log sample_03-06-25_125911.csv\n",
      "Done loading log sample_03-06-25_125911.csv\n",
      "Done loading log sample_03-06-25_133311.csv\n",
      "Done loading log sample_03-06-25_133311.csv\n",
      "Done loading log sample_03-06-25_141354.csv\n",
      "Done loading log sample_03-06-25_141354.csv\n",
      "Done loading log sample_03-06-25_145810.csv\n",
      "Done loading log sample_03-06-25_145810.csv\n",
      "Done loading log sample_03-06-25_153950.csv\n",
      "Done loading log sample_03-06-25_153950.csv\n",
      "Done loading log sample_03-06-25_161614.csv\n",
      "Done loading log sample_03-06-25_161614.csv\n",
      "Done loading log sample_03-07-25_115212.csv\n",
      "Done loading log sample_03-07-25_115212.csv\n",
      "Done loading log sample_03-07-25_122242.csv\n",
      "Done loading log sample_03-07-25_122242.csv\n",
      "Done loading log sample_03-07-25_122326.csv\n",
      "Done loading log sample_03-07-25_122326.csv\n",
      "Done loading log sample_03-07-25_125952.csv\n",
      "Done loading log sample_03-07-25_125952.csv\n",
      "Done loading log sample_03-07-25_130030.csv\n",
      "Done loading log sample_03-07-25_130030.csv\n",
      "Done loading log sample_03-07-25_130123.csv\n",
      "Done loading log sample_03-07-25_130123.csv\n",
      "Done loading log sample_03-07-25_134901.csv\n",
      "Done loading log sample_03-07-25_134901.csv\n",
      "Done loading log sample_03-10-25_122309.csv\n",
      "Done loading log sample_03-10-25_122309.csv\n",
      "Done loading log sample_03-10-25_123426.csv\n",
      "Done loading log sample_03-10-25_123426.csv\n",
      "Done loading log sample_03-10-25_131920.csv\n",
      "Done loading log sample_03-10-25_131920.csv\n",
      "Done loading log sample_03-10-25_135535.csv\n",
      "Done loading log sample_03-10-25_135535.csv\n",
      "Done loading log sample_03-10-25_143530.csv\n",
      "Done loading log sample_03-10-25_143530.csv\n",
      "Done loading log sample_03-11-25_112149.csv\n",
      "Done loading log sample_03-11-25_112149.csv\n",
      "Done loading log sample_03-11-25_115902.csv\n",
      "Done loading log sample_03-11-25_115902.csv\n",
      "Done loading log sample_03-11-25_123845.csv\n",
      "Done loading log sample_03-11-25_123845.csv\n",
      "Done loading log sample_03-11-25_131521.csv\n",
      "Done loading log sample_03-11-25_131521.csv\n",
      "Done loading log sample_03-11-25_135234.csv\n",
      "Done loading log sample_03-11-25_135234.csv\n",
      "Done loading log sample_03-11-25_143341.csv\n",
      "Done loading log sample_03-11-25_143341.csv\n",
      "folder \"Unit 7\"\n",
      "[]\n",
      "Folder .\n",
      "Done loading log sample_03-06-25_122322.csv\n",
      "Done loading log sample_03-06-25_122322.csv\n",
      "Done loading log sample_03-06-25_125609.csv\n",
      "Done loading log sample_03-06-25_125609.csv\n",
      "Done loading log sample_03-06-25_125619.csv\n",
      "Done loading log sample_03-06-25_125619.csv\n",
      "Done loading log sample_03-06-25_130014.csv\n",
      "Done loading log sample_03-06-25_130014.csv\n",
      "Done loading log sample_03-06-25_133415.csv\n",
      "Done loading log sample_03-06-25_133415.csv\n",
      "Done loading log sample_03-06-25_141458.csv\n",
      "Done loading log sample_03-06-25_141458.csv\n",
      "Done loading log sample_03-06-25_145913.csv\n",
      "Done loading log sample_03-06-25_145913.csv\n",
      "Done loading log sample_03-06-25_154052.csv\n",
      "Done loading log sample_03-06-25_154052.csv\n",
      "Done loading log sample_03-06-25_161717.csv\n",
      "Done loading log sample_03-06-25_161717.csv\n",
      "Done loading log sample_03-07-25_115315.csv\n",
      "Done loading log sample_03-07-25_115315.csv\n",
      "Done loading log sample_03-07-25_122345.csv\n",
      "Done loading log sample_03-07-25_122345.csv\n",
      "Done loading log sample_03-07-25_130056.csv\n",
      "Done loading log sample_03-07-25_130056.csv\n",
      "Done loading log sample_03-07-25_135006.csv\n",
      "Done loading log sample_03-07-25_135006.csv\n",
      "Done loading log sample_03-07-25_135016.csv\n",
      "Done loading log sample_03-07-25_135016.csv\n",
      "Done loading log sample_03-10-25_122411.csv\n",
      "Done loading log sample_03-10-25_122411.csv\n",
      "Done loading log sample_03-10-25_123528.csv\n",
      "Done loading log sample_03-10-25_123528.csv\n",
      "Done loading log sample_03-10-25_132022.csv\n",
      "Done loading log sample_03-10-25_132022.csv\n",
      "Done loading log sample_03-10-25_135638.csv\n",
      "Done loading log sample_03-10-25_135638.csv\n",
      "Done loading log sample_03-10-25_143632.csv\n",
      "Done loading log sample_03-10-25_143632.csv\n",
      "Done loading log sample_03-11-25_112252.csv\n",
      "Done loading log sample_03-11-25_112252.csv\n",
      "file sample_03-11-25_120007.csv had 1 rows with bad times, we will use prior time\n",
      "Done loading log sample_03-11-25_120007.csv\n",
      "Done loading log sample_03-11-25_120007.csv\n",
      "Done loading log sample_03-11-25_123946.csv\n",
      "Done loading log sample_03-11-25_123946.csv\n",
      "Done loading log sample_03-11-25_131623.csv\n",
      "Done loading log sample_03-11-25_131623.csv\n",
      "file sample_03-11-25_135339.csv had 1 rows with bad times, we will use prior time\n",
      "Done loading log sample_03-11-25_135339.csv\n",
      "Done loading log sample_03-11-25_135339.csv\n",
      "Done loading log sample_03-11-25_143443.csv\n",
      "Done loading log sample_03-11-25_143443.csv\n"
     ]
    }
   ],
   "source": [
    "#%% Load associated datafile from the unit-logged run\n",
    "# logfile = logfilenames[0];\n",
    "# df_in,df_events = logreader.scanALogfile(logfile)\n",
    "dfraw = logreader.processRootFolder(rootpath,experiments_to_plot);\n",
    "df_events = dfraw[ ~dfraw['Event'].isnull() & ~(dfraw['Event']==' ') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Out Relevant Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Filter\n",
    "df = dfraw;\n",
    "\n",
    "#df = df[df['expname']=='20250311_SimonGhionea_autodl']\n",
    "#df = df[df['unit']=='PM11'];\n",
    "#df = df[df['run']=='sample_03-11-25_153808']\n",
    "#df = df[df['run']=='sample_03-11-25_153400']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Pull out by-cycle information\n",
    "\n",
    "#dfbuildlist = [];\n",
    "def convert_dtypes(df : pd.DataFrame):\n",
    "    # try to convert strings to numerics as appropriate\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col]);\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "buildlist = [];\n",
    "for unit,dfunits in df.groupby('unit'):\n",
    "    #unit_run_counter = 0;\n",
    "    for expname,dfexps in dfunits.groupby('expname'):\n",
    "        for run,dfrun in dfexps.groupby('run'):\n",
    "            #print('unit:{:s} exp:{:} run:{:s} shape:{:s}'.format(unit,expname,run,str(dfrun.shape)))\n",
    "            \n",
    "            dfrunevents = dfrun[ ~dfrun['Event'].isnull() & ~(dfrun['Event']==' ') ]\n",
    "            dfrunevents = dfrunevents[['Time','Event']]\n",
    "            \n",
    "            status = 'nostatus';\n",
    "            text = '';\n",
    "\n",
    "            # Cycle Analysis\n",
    "            evts_beg = dfrunevents[dfrunevents['Event'].str.match(r'^Cycle \\d+ Started')]\n",
    "            evts_end = dfrunevents[dfrunevents['Event'].str.match(r'^Cycle \\d+ Stopped')]\n",
    "            evts_nocyc = dfrunevents.loc[dfrunevents.index.symmetric_difference(evts_beg.index.tolist()+evts_end.index.tolist())]\n",
    "            \n",
    "            if( evts_beg.shape[0]==0 ):\n",
    "                # was not a run\n",
    "                #text+='Not A Run: {:s}'.format(str('\\n'.join(dfrunevents['Event'].to_list())));\n",
    "                text+='Not A Run: {:s}'.format(str(dfrunevents['Event'].to_list()));\n",
    "                status = 'notrun';\n",
    "                if(any(dfrunevents['Event'].str.startswith('Boot'))):\n",
    "                    status = 'bootup';\n",
    "                    \n",
    "                    # check for boot reset reasons\n",
    "                    reset_reason = dict( [tuple(s.split('=')) for s in dfrunevents['Event'].str.extract(r'POWER.RESETREAS=[^\\s]*\\s(.*)').dropna().iloc[0].item().split(' ')] );\n",
    "                    # all reasons 0, I think that means power-on (turned on from switch) based on my reading of Nordic datasheet\n",
    "                    if(all([v=='0' for k,v in reset_reason.items()])):\n",
    "                        status+=',POR';\n",
    "                \n",
    "                dfrunevents['expname'] = expname;\n",
    "                dfrunevents['unit'] = unit;\n",
    "                dfrunevents['run'] = run;\n",
    "                dfrunevents['status'] = status;\n",
    "                dfrunevents['text'] = text;\n",
    "                dfrunevents['Cycle'] = 0;\n",
    "                dfrunevents = dfrunevents.rename(columns={'Time':'TimeBeg'})\n",
    "                #buildlist.append(dfrunevents);\n",
    "                buildlist.append( dfrunevents.drop(columns=['Event']).iloc[[0]] );\n",
    "            \n",
    "            elif( evts_beg.shape[0]==evts_end.shape[0]):\n",
    "                #print('here5')\n",
    "                # all Start and Stopped are matched\n",
    "                ncycles = evts_beg.shape[0];\n",
    "                cyc_num_beg = evts_beg['Event'].str.extract(r'Cycle (\\d+) ',expand=False).astype(np.uint8);\n",
    "                cyc_num_beg.name='Cycle'\n",
    "                cyc_num_end = evts_end['Event'].str.extract(r'Cycle (\\d+) ',expand=False).astype(np.uint8);\n",
    "                cyc_num_end.name='Cycle'\n",
    "                earlyterm = any(evts_end['Event'].str.match(r'.*early\\.'));\n",
    "                if(cyc_num_beg.shape[0]>0):\n",
    "                    fn_lmbda_split_keyvalue_strings = lambda x: dict(tuple([tuple(z.split('=')) for z in x]));\n",
    "\n",
    "                    #cyc_data_beg = evts_beg['Event'].str.extract(r'Cycle \\d.*\\.+( .*)',expand=False).str.split(' ').apply(lambda x: x[1:]).apply(lambda x: dict(tuple([tuple(z.split('=')) for z in x]))).apply(pd.Series)\n",
    "                    #cyc_data_end = evts_end['Event'].str.extract(r'Cycle \\d.*\\.+( .*)',expand=False).str.split(' ').apply(lambda x: x[1:]).apply(lambda x: dict(tuple([tuple(z.split('=')) for z in x]))).apply(pd.Series)\n",
    "                    cyc_data_beg = evts_beg['Event'].str.extract(r'Cycle \\d.*\\.+( .*)',expand=False).str.split(' ');\n",
    "                    if(not all(cyc_data_beg.isna())):\n",
    "                        # there are fields after \"Cycle N started.\" messages\n",
    "                        cyc_data_beg = cyc_data_beg.apply(lambda x: x[1:]).apply(fn_lmbda_split_keyvalue_strings).apply(pd.Series)\n",
    "                        cyc_data_beg = convert_dtypes(cyc_data_beg);\n",
    "\n",
    "                        evts_beg = pd.concat((evts_beg,cyc_num_beg,cyc_data_beg),axis='columns')\n",
    "                        #print('here1');\n",
    "                    else:\n",
    "                        evts_beg = pd.concat((evts_beg,cyc_num_beg),axis='columns');\n",
    "                        #print('here2');\n",
    "                    evts_beg = evts_beg.rename(columns={'Time':'TimeBeg'})\n",
    "\n",
    "\n",
    "                    cyc_data_end = evts_end['Event'].str.extract(r'Cycle \\d.*\\.+( .*)',expand=False).str.split(' ');\n",
    "                    if(not all(cyc_data_end.isna())):\n",
    "                        # there are fields after \"Cycle N started.\" messages\n",
    "                        cyc_data_end = cyc_data_end.apply(lambda x: x[1:]).apply(fn_lmbda_split_keyvalue_strings).apply(pd.Series)\n",
    "                        cyc_data_end = convert_dtypes(cyc_data_end);\n",
    "\n",
    "                        evts_end = pd.concat((evts_end,cyc_num_end,cyc_data_end),axis='columns')\n",
    "                        #print('here3')\n",
    "                    else:\n",
    "                        evts_end = pd.concat((evts_end,cyc_num_end),axis='columns');\n",
    "                        #print('here4');\n",
    "                    evts_end = evts_end.rename(columns={'Time':'TimeEnd'})\n",
    "\n",
    "                    # Combine Beginning and Ending of cycle information into a single cycle row\n",
    "                    cyc_data = pd.merge(evts_beg,evts_end,on='Cycle',suffixes=('Beg','End')).set_index('Cycle',drop=True);\n",
    "\n",
    "                    # calculate cycle information\n",
    "                    cyc_data['CCycleRTCSeconds'] = (cyc_data['TimeEnd']-cyc_data['TimeBeg']).apply(lambda x: x.total_seconds());\n",
    "                    #cyc_data.loc[0,['EventEnd']] = 'norm'\n",
    "                else:\n",
    "                    print('\\tOTHER')\n",
    "\n",
    "                \n",
    "                if(earlyterm):                   \n",
    "                    # print('\\tEarly abort in cycle {:d} @ {:.0f} s @ total runtime {:.0f} s:'.format(\n",
    "                    #     cyc_data.index[-1],\n",
    "                    #     cyc_data['CalcCycleRTCSeconds'].iloc[-1].item(),\n",
    "                    #     cyc_data['CalcCycleRTCSeconds'].sum().item()\n",
    "                    #     )\n",
    "                    # )\n",
    "                    text += 'Early abort in cycle {:d} @ {:.0f} s @ total runtime {:.0f} s:\\n'.format(\n",
    "                        cyc_data.index[-1],\n",
    "                        cyc_data['CCycleRTCSeconds'].iloc[-1].item(),\n",
    "                        cyc_data['CCycleRTCSeconds'].sum().item()\n",
    "                    );\n",
    "                    #print('\\t',str(evts_nocyc['Event'].to_list()))\n",
    "                    #text += '{:s}'.format('\\n'.join(evts_nocyc['Event'].to_list()));\n",
    "                    text += '{:s}'.format(str(evts_nocyc['Event'].to_list()));\n",
    "                    normal_interruptions = [\n",
    "                        'HALL sensor interrupted',\n",
    "                        'Optical sensor interrupted',\n",
    "                        'ButtonCycle cancled via button click',\n",
    "                    ]\n",
    "                    if(any(pd.concat([evts_nocyc['Event'].str.contains(s) for s in normal_interruptions]))):\n",
    "                        status = 'run_ended_early_user';\n",
    "                    else:\n",
    "                        status = 'run_ended_early_other';\n",
    "                    # if(evts_nocyc['Event'].str.contains('Optical sensor interrupted')|evts_nocyc['Event'].str.contains('Hall sensor interrupted')):\n",
    "                    #     status = 'run_ended_early';\n",
    "                else:\n",
    "                    # print('\\tCompletedRun @ total runtime {:.0f} s'.format(\n",
    "                    #     cyc_data['CalcCycleRTCSeconds'].sum().item()\n",
    "                    # ))\n",
    "                    text += 'CompletedRun @ total runtime {:.0f}s:'.format(\n",
    "                        cyc_data['CCycleRTCSeconds'].sum().item()\n",
    "                    )\n",
    "                    #text += '{:s}'.format('\\n'.join(evts_nocyc['Event'].to_list()));\n",
    "                    text += '{:s}'.format(str(evts_nocyc['Event'].to_list()));\n",
    "                    status = 'run_success';\n",
    "                \n",
    "                try:\n",
    "                    if(not earlyterm):\n",
    "                        if( not all(cyc_data_beg['runtime_s']==cyc_data_end['expected_sec']) ):\n",
    "                            #print('\\tMismatched runtimes');\n",
    "                            text += '\\n\\tMismatched runtimes';\n",
    "                            status = 'run_mismatched_runtimes';\n",
    "                    else:\n",
    "                        if( not all(cyc_data_beg['runtime_s'][0:-1]==cyc_data_end['expected_sec'][0:-1]) ):\n",
    "                            #print('\\tMismatched runtimes (early)');\n",
    "                            text += '\\n\\tMismatched runtimes (early)';\n",
    "                            status = 'run_mismatched_runtimes_early';\n",
    "                except:\n",
    "                    pass;\n",
    "                \n",
    "                # SUMMARIZE PER RUN\n",
    "                if(not earlyterm):\n",
    "                    pass;\n",
    "                    # for (k1,v1),(k2,v2) in zip(evts_beg.iterrows(),evts_end.iterrows()):\n",
    "                    #     #print( 'Cycle{:d} idx{:d} to idx{:d}'.format(v1['Cycle'],k1,k2) );\n",
    "                        \n",
    "                    #     # subset this cycle in the run\n",
    "                    #     dfruncyc = dfrun.loc[k1:k2]\n",
    "\n",
    "                    #     # last third\n",
    "                    #     dfruncyclst3rd = dfruncyc.loc[k2-((k2-k1)//3):]\n",
    "\n",
    "                    #     # calculate some summaries\n",
    "                    #     #cyc_data.loc[v1['Cycle'],'C'] = cyc_data['CCycleRTCSeconds'].sum().item()\n",
    "                    #     cyc_data.loc[v1['Cycle'],'CL3MedAmpTemp'] = dfruncyclst3rd['AmpTemp'].median()\n",
    "                    #     cyc_data.loc[v1['Cycle'],'CL3MedValveTemp'] = dfruncyclst3rd['ValveTemp'].median()\n",
    "                    #     cyc_data.loc[v1['Cycle'],'CL3MaxAmpPWM'] = dfruncyclst3rd['AmpPWM'].max()\n",
    "                    #     cyc_data.loc[v1['Cycle'],'CL3MaxValvePWM'] = dfruncyclst3rd['ValvePWM'].max()\n",
    "                    #     cyc_data.loc[v1['Cycle'],'CMaxAmpTemp'] = dfruncyc['AmpTemp'].max()\n",
    "                    #     cyc_data.loc[v1['Cycle'],'CMaxValveTemp'] = dfruncyc['ValveTemp'].max()\n",
    "\n",
    "                    #     pass\n",
    "                for (k1,v1),(k2,v2) in zip(evts_beg.iterrows(),evts_end.iterrows()):\n",
    "                    #print( 'Cycle{:d} idx{:d} to idx{:d}'.format(v1['Cycle'],k1,k2) );\n",
    "                    \n",
    "                    # subset this cycle in the run\n",
    "                    dfruncyc = dfrun.loc[k1:k2]\n",
    "\n",
    "                    # last third\n",
    "                    dfruncyclst3rd = dfruncyc.loc[k2-((k2-k1)//3):]\n",
    "\n",
    "                    # calculate some summaries\n",
    "                    #cyc_data.loc[v1['Cycle'],'C'] = cyc_data['CCycleRTCSeconds'].sum().item()\n",
    "                    #cyc_data.loc[v1['Cycle'],'C'] = cyc_data['CCycleRTCSeconds'].sum().item()\n",
    "                    cyc_data.loc[v1['Cycle'],'CL3MedAmpTemp'] = dfruncyclst3rd['AmpTemp'].median()\n",
    "                    cyc_data.loc[v1['Cycle'],'CL3MedValveTemp'] = dfruncyclst3rd['ValveTemp'].median()\n",
    "                    cyc_data.loc[v1['Cycle'],'CL3MaxAmpPWM'] = dfruncyclst3rd['AmpPWM'].max()\n",
    "                    cyc_data.loc[v1['Cycle'],'CL3MaxValvePWM'] = dfruncyclst3rd['ValvePWM'].max()\n",
    "                    cyc_data.loc[v1['Cycle'],'CMaxAmpTemp'] = dfruncyc['AmpTemp'].max()\n",
    "                    cyc_data.loc[v1['Cycle'],'CMaxValveTemp'] = dfruncyc['ValveTemp'].max()\n",
    "\n",
    "                    pass\n",
    "                #cyc_data['CRTCRuntime'] = (dfrun['Time'].iloc[[0,-1]]).diff().apply(lambda x: x.total_seconds()).iloc[-1].item();\n",
    "                cyc_data['CRTCRuntime'] = ( cyc_data.iloc[-1]['TimeEnd'] - cyc_data.iloc[0]['TimeBeg'] ).total_seconds();\n",
    "\n",
    "                cyc_data['expname'] = expname;\n",
    "                cyc_data['unit'] = unit;\n",
    "                cyc_data['run'] = run;\n",
    "                cyc_data['status'] = status;\n",
    "                cyc_data['text'] = text;\n",
    "                buildlist.append(cyc_data.reset_index());\n",
    "            else:\n",
    "                text += 'Run cycles non-sensical, nbegun={:d} nended={:d}'.format(evts_beg.shape[0],evts_end.shape[0]);\n",
    "                status = 'nonsensical_cycles';\n",
    "\n",
    "                dfrunevents['expname'] = expname;\n",
    "                dfrunevents['unit'] = unit;\n",
    "                dfrunevents['run'] = run;\n",
    "                dfrunevents['status'] = status;\n",
    "                dfrunevents['text'] = text;\n",
    "                dfrunevents['Cycle'] = 0;\n",
    "                dfrunevents.rename(columns={'Time':'TimeBeg'});\n",
    "                buildlist.append(dfrunevents);\n",
    "\n",
    "            if(status == 'notrun'):\n",
    "                print('unit:{:s} exp:{:} run:{:s} shape:{:s} status:{:s}'.format(unit,expname,run,str(dfrun.shape),status))\n",
    "                print(text)\n",
    "            #break;\n",
    "\n",
    "\n",
    "#dflifetest = pd.concat(dfbuildlist)\n",
    "dfbuilt = pd.concat(buildlist,ignore_index=True)\n",
    "dfbuilt['Cycle'] = dfbuilt['Cycle'].astype(np.uint8)\n",
    "dfbuilt = dfbuilt.set_index(['unit','expname','run','Cycle'])\n",
    "#dfbuilt = pd.concat(buildlist).reset_index()\n",
    "\n",
    "#%% Show run summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI Playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Output Summary Table By Unit\n",
    "\n",
    "mydf = dfbuilt.reorder_levels(['expname','unit','run','Cycle']);\n",
    "# mydf = dfbuilt.reset_index().set_index(['expname','unit']);\n",
    "# mydf = mydf[['run','Cycle','TimeBeg','TimeEnd','status','text']];\n",
    "#mydf = dfbuilt.reset_index().set_index(['expname','unit']);\n",
    "#mydf = dfbuilt.reset_index()\n",
    "#mydf = mydf[['run','Cycle','TimeBeg','status','text']];\n",
    "\n",
    "#mydf.apply(lambda x: '<a href=\"file:///c:\\\\TEMP\\\\runtime_{:s}_{:s}_{:s}.html\">link</a>'.format( x['exp'],'b','c' ),axis=1)\n",
    "def mkrunlink(x):\n",
    "    if((x['status'] == 'run_success') or (x['status'].find('run_ended_early')>=0)):\n",
    "        return '<a href=\"file:///c:\\\\TEMP\\\\NAATOS_PM_RUN_runtime_{:s}_{:s}_{:s}.html\" target=\"_blank\">{:s}</a>'.format( x['expname'],x['unit'],x['run'],x['run'] );\n",
    "    else:\n",
    "        return x['run'];\n",
    "    #return 'test';\n",
    "ret = dfbuilt.reset_index().apply( lambda x: mkrunlink(x) ,axis=1);\n",
    "mydf['run'] = ret.tolist();\n",
    "\n",
    "# simplify Time field\n",
    "#ret = mydf.reset_index().apply( lambda x: x['TimeBeg'] if pd.isna(x['Time'])==True else x['Time'],axis=1);\n",
    "#mydf['Time'] = ret.tolist();\n",
    "\n",
    "# Choose Columns\n",
    "mydf = mydf[['status','TimeBeg',*dfbuilt.columns[dfbuilt.columns.str.startswith('C')].tolist(),'text']];\n",
    "#mydf = mydf[mydf['status']=='notrun'];\n",
    "mydf = mydf.reset_index();\n",
    "mydf = mydf.sort_values(['expname','TimeBeg','Cycle'])\n",
    "\n",
    "# STYLING\n",
    "def style_statustext(val):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property\n",
    "    \"\"\"\n",
    "    if(val=='run_success'):\n",
    "        return \"background-color: lightgreen\";\n",
    "    elif(val=='run_ended_early_user'):\n",
    "        return \"background-color: lightyellow\";\n",
    "    elif(val=='notrun'):\n",
    "        return '';\n",
    "    elif(val.find('boot')>=0):\n",
    "        return \"background-color: powderblue\";\n",
    "    else:\n",
    "        return \"background-color: orchid\";\n",
    "mydf_styled = mydf.style.map(style_statustext,subset=pd.IndexSlice[:, ['status']]);\n",
    "\n",
    "header_filters = {\n",
    "    'text': {'type': 'input', 'func': 'like', 'placeholder': 'Search text'},\n",
    "}\n",
    "tabulator_editors = {\n",
    "    'unit': {'type': 'list', 'valuesLookup': True},\n",
    "    'status': {'type': 'list', 'valuesLookup': True},\n",
    "    'text': {'type': 'input', 'func': 'like', 'placeholder': 'Search text'},\n",
    "}\n",
    "pn_summarytable = pn.widgets.Tabulator(\n",
    "    value=mydf_styled,\n",
    "\n",
    "    pagination='local', page_size=30,\n",
    "    #pagination='local',page_size=1000,\n",
    "\n",
    "    #hierarchical=True,\n",
    "    #groupby=['expname','unit'],\n",
    "    #theme='midnight',\n",
    "    #aggregators={\"origin\": \"mean\", \"yr\": \"mean\"},\n",
    "    \n",
    "    formatters = {\n",
    "        'run': dict(type='html'),\n",
    "        'text': dict(type='textarea'),\n",
    "    },\n",
    "\n",
    "    #header_filters=header_filters,\n",
    "    editors=tabulator_editors,header_filters=True,\n",
    "\n",
    "    configuration=dict(\n",
    "        paginationCounter=\"rows\"\n",
    "    ),\n",
    "    \n",
    "    sizing_mode='stretch_both',\n",
    ");\n",
    "# pn_summarytable = pn.widgets.DataFrame(\n",
    "#     value=mydf,\n",
    "#     hierarchical=True,\n",
    "#     sizing_mode='stretch_both', width_policy='max',autosize_mode='fit_viewport'\n",
    "# );\n",
    "\n",
    "pn_final = pn.Column(pn_summarytable).servable();\n",
    "#pn_final.save(r'C:\\TEMP\\summaryinfo.html');\n",
    "#pn_final\n",
    "pn.serve(pn_final);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf[mydf['status'].str.startswith('boot')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel Multi-Page Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page1():\n",
    "    return \"page 1\"\n",
    "\n",
    "def page2():\n",
    "    return pn.Column(\n",
    "        \"# Page 2\", \"Welcome to the second page\"\n",
    "    )\n",
    "ROUTES = {\n",
    "    \"1\": page1, \"2\": page2\n",
    "}\n",
    "pn.serve(ROUTES, port=5006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffull = dfbuilt.reset_index().copy();\n",
    "dffullorig = dffull.copy(); #<-- store a copy so we can come back to this\n",
    "dfsel = pd.DataFrame();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Helpers\n",
    "def filtered_dataframe(param_values,param_columns):\n",
    "    \n",
    "    selection_dict = pd.Series(param_values)[list(param_columns.keys())].to_dict();\n",
    "    print('selection_dict',selection_dict);\n",
    "\n",
    "    # this line will filter the dataframe using param_values and param_columns\n",
    "    #dffiltered = dffull.isin(pd.Series(obj.param.values())[param_columns.keys()].to_dict())[param_columns].all(axis=1);\n",
    "    #dffiltered = dffull[dffull.isin(pd.Series(param_values)[param_columns.keys()].to_dict())[param_columns].all(axis=1)]\n",
    "\n",
    "    dffiltered = dffull[dffull.isin(selection_dict)[param_columns.keys()].all(axis=1)]\n",
    "    \n",
    "    return dffiltered;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import param\n",
    "class ExplorerApp(param.Parameterized):\n",
    "    data = param.DataFrame(doc=\"Stores a DataFrame to explore\")\n",
    "\n",
    "    columns = param.ListSelector(\n",
    "        default=[\"unit\",\"expname\",\"run\",\"Cycle\",\"TimeBeg\",\"status\",\"text\"]\n",
    "    )\n",
    "\n",
    "    filtered_data = param.DataFrame(doc=\"Stores the filtered DataFrame\");\n",
    "\n",
    "    actionbutton = param.Action(lambda x: x.param.trigger('actionbutton'), label='Update table');\n",
    "    refinebutton = param.Action(lambda x: x.param.trigger('refinebutton'), label='Refine selection');\n",
    "    resetchoices = param.Action(lambda x: x.param.trigger('resetchoices'), label='Reset choices');\n",
    "\n",
    "    _widget_tabulator = pn.widgets.Tabulator(\n",
    "        name='DataFrame',\n",
    "        selectable='checkbox',\n",
    "        disabled=True, # non-editable data\n",
    "        show_index=False,\n",
    "        layout='fit_data', # auto-fit\n",
    "        #pagination = None,\n",
    "        pagination = 'remote',\n",
    "        page_size=25,\n",
    "    );\n",
    "\n",
    "    _pane_main = pn.pane.Str('test');\n",
    "    _pane_idx = None;\n",
    "\n",
    "    def _cb_select_all(self,event, tabulator_widget, selectAll=True):\n",
    "        if(selectAll):\n",
    "            tabulator_widget.selection = list(range(len(tabulator_widget.value)));\n",
    "        else:\n",
    "            tabulator_widget.selection = [];\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs); # MUST CALL SUPER constructor for panel to work\n",
    "\n",
    "        # define columns\n",
    "        self.param.columns.objects = dffull.columns.to_list()\n",
    "\n",
    "        # add dataframe interactivity\n",
    "        dfrx = self.param.data.rx();\n",
    "\n",
    "        # filtered dataframe\n",
    "        #self.filtered_data = dfrx[self.param.columns];\n",
    "\n",
    "\n",
    "        # self._pane_main = pn.Tabs(\n",
    "        #     #('idx',self._widget_tabulator),\n",
    "        #     ('idx',self._pane_idx),\n",
    "        #     ('gallery','TEST2!'),\n",
    "        #     ('detail','TEST3!'),\n",
    "        #     dynamic=True,\n",
    "        #     tabs_location='above',\n",
    "        # );\n",
    "\n",
    "    @param.depends(\"columns\", watch=True, on_init=True)\n",
    "    def _update_filtered_data(self):\n",
    "        df = self.data\n",
    "        self.filtered_data=df[\n",
    "            self.columns\n",
    "        ]\n",
    "\n",
    "    @param.depends('data')\n",
    "    def _mk_tabulator_widget(self):\n",
    "        def mkrunlink(x):\n",
    "            if((x['status'] == 'run_success') or (x['status'].find('run_ended_early')>=0)):\n",
    "                return '<a href=\"file:///c:\\\\TEMP\\\\NAATOS_PM_RUN_runtime_{:s}_{:s}_{:s}.html\" target=\"_blank\">{:s}</a>'.format( x['expname'],x['unit'],x['run'],x['run'] );\n",
    "            else:\n",
    "                return x['run'];\n",
    "            #return 'test';\n",
    "        mydf = self.filtered_data;\n",
    "        ret = mydf.reset_index().apply( lambda x: mkrunlink(x) ,axis=1);\n",
    "        mydf['run'] = ret.tolist();\n",
    "\n",
    "        # simplify Time field\n",
    "        #ret = mydf.reset_index().apply( lambda x: x['TimeBeg'] if pd.isna(x['Time'])==True else x['Time'],axis=1);\n",
    "        #mydf['Time'] = ret.tolist();\n",
    "\n",
    "        # Choose Columns\n",
    "        #mydf = mydf[['status','TimeBeg',*dfbuilt.columns[dfbuilt.columns.str.startswith('C')].tolist(),'text']];\n",
    "        #mydf = mydf[mydf['status']=='notrun'];\n",
    "        mydf = mydf.reset_index();\n",
    "        mydf = mydf.sort_values(['expname','TimeBeg','Cycle'])\n",
    "\n",
    "        # STYLING\n",
    "        def style_statustext(val):\n",
    "            \"\"\"\n",
    "            Takes a scalar and returns a string with\n",
    "            the css property\n",
    "            \"\"\"\n",
    "            if(val=='run_success'):\n",
    "                return \"background-color: lightgreen\";\n",
    "            elif(val=='run_ended_early_user'):\n",
    "                return \"background-color: lightyellow\";\n",
    "            elif(val=='notrun'):\n",
    "                return '';\n",
    "            elif(val.find('boot')>=0):\n",
    "                return \"background-color: powderblue\";\n",
    "            else:\n",
    "                return \"background-color: orchid\";\n",
    "        mydf_styled = mydf.style.map(style_statustext,subset=pd.IndexSlice[:, ['status']]);\n",
    "\n",
    "        header_filters = {\n",
    "            'text': {'type': 'input', 'func': 'like', 'placeholder': 'Search text'},\n",
    "        }\n",
    "        tabulator_editors = {\n",
    "            'unit': {'type': 'list', 'valuesLookup': True},\n",
    "            'status': {'type': 'list', 'valuesLookup': True},\n",
    "            'text': {'type': 'input', 'func': 'like', 'placeholder': 'Search text'},\n",
    "        }\n",
    "        pn_summarytable = pn.widgets.Tabulator(\n",
    "            value=mydf_styled,\n",
    "\n",
    "            pagination='local', page_size=30,\n",
    "            #pagination='local',page_size=1000,\n",
    "\n",
    "            #hierarchical=True,\n",
    "            #groupby=['expname','unit'],\n",
    "            #theme='midnight',\n",
    "            #aggregators={\"origin\": \"mean\", \"yr\": \"mean\"},\n",
    "            \n",
    "            formatters = {\n",
    "                'run': dict(type='html'),\n",
    "                'text': dict(type='textarea'),\n",
    "            },\n",
    "\n",
    "            #header_filters=header_filters,\n",
    "            editors=tabulator_editors,header_filters=True,\n",
    "\n",
    "            configuration=dict(\n",
    "                paginationCounter=\"rows\"\n",
    "            ),\n",
    "            \n",
    "            sizing_mode='stretch_both',\n",
    "        );\n",
    "        return pn_summarytable;\n",
    "\n",
    "    @param.depends('refinebutton', watch=True)\n",
    "    def _refine_choices(self):\n",
    "        global dffull;\n",
    "        #dffullorig = dffull.copy(); # keep original, as we will be filtering dffull later\n",
    "        #print('Refine choices');\n",
    "        #print(self.param.values());\n",
    "        #print(param_columns);\n",
    "        dffull = filtered_dataframe(self.param.values(), param_columns);\n",
    "        print('Refine choices dffull.shape',dffull.shape);\n",
    "        update_or_add_parameters(param_columns);\n",
    "        #self._widget_tabulator.value = dffull.drop(columns=['fyuv','fjpg']);\n",
    "        self._widget_tabulator.value = dffull;\n",
    "        #print(self.param['ctrl_ghl_agc']);\n",
    "        \n",
    "    @param.depends('resetchoices', watch=True)\n",
    "    def _reset_choices(self):\n",
    "        global dffull;\n",
    "        dffull = dffullorig.copy();\n",
    "        update_or_add_parameters(param_columns);\n",
    "\n",
    "    # callback - fires when the button is clicked\n",
    "    @param.depends('actionbutton', watch=True)\n",
    "    def _update_figure(self):\n",
    "        global dffull;\n",
    "        print('_update_figure()');\n",
    "\n",
    "        self._refine_choices();\n",
    "\n",
    "        #self.build_gallery();\n",
    "        print('Update Figure')\n",
    "\n",
    "    # # callback - fires when dataframe selection is edited\n",
    "    # @param.depends('_widget_tabulator.selection', watch=True)\n",
    "    # def _tabulator_selection_change(self):\n",
    "    #     print('df selection',self._widget_tabulator.selection);\n",
    "\n",
    "    #\n",
    "    def __panel__(self):\n",
    "        pn_but_idx_selall = pn.widgets.Button(name='Select All', button_type='primary');\n",
    "        pn_but_idx_selall.on_click(lambda event: self._cb_select_all(event,self._widget_tabulator,True));\n",
    "                                   \n",
    "        pn_but_idx_selnone = pn.widgets.Button(name='Select None', button_type='primary');\n",
    "        # pn_but_idx_selall.on_click(lambda event:\n",
    "        #     setattr(self._widget_tabulator,'selection',[]),\n",
    "        # )\n",
    "        pn_but_idx_selnone.on_click(lambda event: self._cb_select_all(event,self._widget_tabulator,False));\n",
    "\n",
    "\n",
    "        return pn.Column(\n",
    "                pn.Row(pn_but_idx_selall,pn_but_idx_selnone),\n",
    "                #self._widget_tabulator,\n",
    "                self._mk_tabulator_widget()\n",
    "            )\n",
    "\n",
    "#%% Panel creation\n",
    "# which columns will we use?\n",
    "param_columns = {\n",
    "    'expname':param.ListSelector,\n",
    "    'unit':param.ListSelector,\n",
    "}\n",
    "# # all control columns\n",
    "# for cname in dffull.columns[dffull.columns.str.startswith('ctrl_')].tolist():\n",
    "#     param_columns[cname] = param.ListSelector;\n",
    "\n",
    "# create the panel object\n",
    "obj = ParametricRawViewApp(data=dffull);\n",
    "def update_or_add_parameters(param_columns):\n",
    "    for col,paramobj in param_columns.items():\n",
    "        items = dffull[col].unique().tolist();\n",
    "        \n",
    "        if col not in obj.param:\n",
    "            # add parameter\n",
    "            newParam = paramobj(default=items,objects=items);\n",
    "            print('Adding param',col,'dffull.shape',dffull.shape)\n",
    "            obj.param.add_parameter(col,newParam);\n",
    "        else:\n",
    "            # update parameter\n",
    "            print('Updating param',col,'dffull.shape',dffull.shape)\n",
    "            # reset available options\n",
    "            obj.param[col].objects = items;\n",
    "            # reset selections (to all)\n",
    "            setattr(obj,col,items);\n",
    "update_or_add_parameters(param_columns);\n",
    "\n",
    "# format params, customize widgets\n",
    "# formatted_params = pn.Param(obj.param, widgets={\n",
    "#         'stimstr': {'height':250},\n",
    "#         'surfgen': {'height':50},\n",
    "#         'opt_method': {'height':50},\n",
    "#         'opt_measured_v_i': {'height':50},\n",
    "#         #'mdln': {'height':50},\n",
    "#         's_spec': {'height':50},\n",
    "#     },\n",
    "#     width=300\n",
    "# )\n",
    "formatted_params = pn.Param(obj.param,\n",
    "    width=300,\n",
    "    widgets={\"columns\": pn.widgets.MultiChoice}\n",
    ")\n",
    "\n",
    "#%% Final\n",
    "pn_final = pn.Row(\n",
    "    #obj.param, obj.view,\n",
    "    formatted_params, obj\n",
    "    #width_policy='max',\n",
    "    #height_policy='max',\n",
    ").servable(\"GHL NAATOS Module Logs Explorer\")\n",
    "pn.serve(pn_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameterized 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffull = dfbuilt.reset_index().copy();\n",
    "dffullorig = dffull.copy(); #<-- store a copy so we can come back to this\n",
    "dfsel = pd.DataFrame();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Helpers\n",
    "def filtered_dataframe(param_values,param_columns):\n",
    "    \n",
    "    selection_dict = pd.Series(param_values)[list(param_columns.keys())].to_dict();\n",
    "    print('selection_dict',selection_dict);\n",
    "\n",
    "    # this line will filter the dataframe using param_values and param_columns\n",
    "    #dffiltered = dffull.isin(pd.Series(obj.param.values())[param_columns.keys()].to_dict())[param_columns].all(axis=1);\n",
    "    #dffiltered = dffull[dffull.isin(pd.Series(param_values)[param_columns.keys()].to_dict())[param_columns].all(axis=1)]\n",
    "\n",
    "    dffiltered = dffull[dffull.isin(selection_dict)[param_columns.keys()].all(axis=1)]\n",
    "    \n",
    "    return dffiltered;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding param expname dffull.shape (493, 19)\n",
      "Adding param unit dffull.shape (493, 19)\n",
      "Adding param status dffull.shape (493, 19)\n",
      "Adding param Cycle dffull.shape (493, 19)\n",
      "DateRange\n",
      "Adding param TimeBeg dffull.shape (493, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SimonGhionea\\AppData\\Local\\Temp\\ipykernel_20548\\3170679435.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['run'] = ret.tolist();\n"
     ]
    }
   ],
   "source": [
    "from panel.viewable import Viewer\n",
    "import param\n",
    "\n",
    "data_url = \"https://assets.holoviz.org/panel/tutorials/turbines.csv.gz\"\n",
    "#turbines = pn.cache(pd.read_csv)(data_url)\n",
    "\n",
    "c_def_cols = [\"unit\",\"expname\",\"run\",\"Cycle\",\"TimeBeg\",\"status\",\"text\"];\n",
    "c_filters = {\n",
    "    \"expname\":param.ListSelector,\n",
    "    \"unit\":param.ListSelector,\n",
    "    \"status\":param.ListSelector,\n",
    "    \"Cycle\":param.ListSelector,\n",
    "    \"TimeBeg\":param.DateRange\n",
    "};\n",
    "\n",
    "def update_or_add_parameters(obj,param_columns):\n",
    "    for col,paramobj in param_columns.items():\n",
    "        items = dffull[col].unique().tolist();\n",
    "        \n",
    "        if(paramobj == param.ListSelector):\n",
    "            if col not in obj.param:\n",
    "                # add parameter\n",
    "                newParam = paramobj(default=sorted(items),objects=sorted(items));\n",
    "                print('Adding param',col,'dffull.shape',dffull.shape)\n",
    "                obj.param.add_parameter(col,newParam);\n",
    "            else:\n",
    "                # update parameter\n",
    "                print('Updating param',col,'dffull.shape',dffull.shape)\n",
    "                # reset available options\n",
    "                obj.param[col].objects = items;\n",
    "                # reset selections (to all)\n",
    "                setattr(obj,col,items);\n",
    "        elif(paramobj == param.DateRange):\n",
    "            print('DateRange')\n",
    "            if col not in obj.param:\n",
    "                # add parameter\n",
    "                beg = sorted(dffull['TimeBeg'].unique())[0];\n",
    "                end = sorted(dffull['TimeBeg'].unique(),reverse=True)[0];\n",
    "                newParam = paramobj(default=(beg,end),bounds=(beg,end));\n",
    "                print('Adding param',col,'dffull.shape',dffull.shape)\n",
    "                obj.param.add_parameter(col,newParam);\n",
    "\n",
    "class DataExplorer(Viewer):\n",
    "    data = param.DataFrame(doc=\"Stores a DataFrame to explore\")\n",
    "\n",
    "    columns = param.ListSelector(\n",
    "        #default=[\"p_name\", \"t_state\", \"t_county\", \"p_year\", \"t_manu\", \"p_cap\"]\n",
    "        default=c_def_cols,\n",
    "    )\n",
    "\n",
    "    #year = param.Range(default=(1981, 2022), bounds=(1981, 2022))\n",
    "    #capacity = param.Range(default=(0, 1100), bounds=(0, 1100))\n",
    "\n",
    "    filtered_data = param.DataFrame(doc=\"Stores the filtered DataFrame\")\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        \n",
    "        # set parameter for columns to those from dataframe\n",
    "        self.param.columns.objects = self.data.columns.to_list()\n",
    "\n",
    "        # dynamically add parameters\n",
    "        update_or_add_parameters(self,c_filters);\n",
    "\n",
    "    @param.depends(\"data\", \"columns\", watch=True, on_init=True)\n",
    "    def _update_filtered_data(self):\n",
    "        df = self.data\n",
    "        # self.filtered_data=df[df.p_year.between(*self.year) & df.p_cap.between(*self.capacity)][\n",
    "        #     self.columns\n",
    "        # ]\n",
    "    \n",
    "\n",
    "        # after filtering\n",
    "        df = df[ self.columns ];\n",
    "    \n",
    "        # styler\n",
    "        # # STYLING\n",
    "        # def style_statustext(val):\n",
    "        #     \"\"\"\n",
    "        #     Takes a scalar and returns a string with\n",
    "        #     the css property\n",
    "        #     \"\"\"\n",
    "        #     if(val=='run_success'):\n",
    "        #         return \"background-color: lightgreen\";\n",
    "        #     elif(val=='run_ended_early_user'):\n",
    "        #         return \"background-color: lightyellow\";\n",
    "        #     elif(val=='notrun'):\n",
    "        #         return '';\n",
    "        #     elif(val.find('boot')>=0):\n",
    "        #         return \"background-color: powderblue\";\n",
    "        #     else:\n",
    "        #         return \"background-color: orchid\";\n",
    "        # mydf_styled = df.style.map(style_statustext,subset=pd.IndexSlice[:, ['status']]);\n",
    "    \n",
    "        # some formatting\n",
    "        def mkrunlink(x):\n",
    "            if((x['status'] == 'run_success') or (x['status'].find('run_ended_early')>=0)):\n",
    "                return '<a href=\"file:///c:\\\\TEMP\\\\NAATOS_PM_RUN_runtime_{:s}_{:s}_{:s}.html\" target=\"_blank\">{:s}</a>'.format( x['expname'],x['unit'],x['run'],x['run'] );\n",
    "            else:\n",
    "                return x['run'];\n",
    "            #return 'test';\n",
    "        ret = df.apply( lambda x: mkrunlink(x) ,axis=1);\n",
    "        df['run'] = ret.tolist();\n",
    "\n",
    "        self.filtered_data = df;\n",
    "\n",
    "\n",
    "    @param.depends('filtered_data')\n",
    "    def number_of_rows(self):\n",
    "        return f\"Rows: {len(self.filtered_data)}\"\n",
    "    \n",
    "    def _tabulatorWidget(self):\n",
    "        print('_tabulatorWidget called');\n",
    "\n",
    "        header_filters = {\n",
    "            'text': {'type': 'input', 'func': 'like', 'placeholder': 'Search text'},\n",
    "        }\n",
    "        tabulator_editors = {\n",
    "            'unit': {'type': 'list', 'valuesLookup': True},\n",
    "            'status': {'type': 'list', 'valuesLookup': True},\n",
    "            'text': {'type': 'input', 'func': 'like', 'placeholder': 'Search text'},\n",
    "        }\n",
    "        pn_summarytable = pn.widgets.Tabulator(\n",
    "            value=self.param.filtered_data,\n",
    "\n",
    "            pagination='local', page_size=30,\n",
    "            #pagination='local',page_size=1000,\n",
    "\n",
    "            #hierarchical=True,\n",
    "            #groupby=['expname','unit'],\n",
    "            #theme='midnight',\n",
    "            #aggregators={\"origin\": \"mean\", \"yr\": \"mean\"},\n",
    "            show_index=False,\n",
    "            formatters = {\n",
    "                'run': dict(type='html'),\n",
    "                'text': dict(type='textarea'),\n",
    "            },\n",
    "\n",
    "            #header_filters=header_filters,\n",
    "            editors=tabulator_editors,header_filters=True,\n",
    "\n",
    "            configuration=dict(\n",
    "                paginationCounter=\"rows\"\n",
    "            ),\n",
    "            \n",
    "            sizing_mode='stretch_both',\n",
    "        );\n",
    "\n",
    "        # apply dataframe styling to the tabulator widget\n",
    "        # https://discourse.holoviz.org/t/dynamic-update-of-tabulator-style/2741\n",
    "        # STYLING\n",
    "        def style_statustext(val):\n",
    "            \"\"\"\n",
    "            Takes a scalar and returns a string with\n",
    "            the css property\n",
    "            \"\"\"\n",
    "            if(val=='run_success'):\n",
    "                return \"background-color: lightgreen\";\n",
    "            elif(val=='run_ended_early_user'):\n",
    "                return \"background-color: lightyellow\";\n",
    "            elif(val=='notrun'):\n",
    "                return '';\n",
    "            elif(val.find('boot')>=0):\n",
    "                return \"background-color: powderblue\";\n",
    "            else:\n",
    "                return \"background-color: orchid\";\n",
    "        mydf_styled = pn_summarytable.style.map(style_statustext,subset=pd.IndexSlice[:, ['status']]);\n",
    "\n",
    "\n",
    "        return pn_summarytable;\n",
    "\n",
    "    def __panel__(self):\n",
    "        print('__panel__() method called')\n",
    "        c_display = set(obj.param.values().keys())-set(('columns','data','filtered_data','name'));\n",
    "        \n",
    "        return pn.Column(\n",
    "            pn.Row(\n",
    "                pn.Column(\n",
    "                    pn.widgets.MultiChoice.from_param(self.param.columns, width=400),\n",
    "                ),\n",
    "                #pn.Column(self.param.year, self.param.capacity),\n",
    "                *[obj.param[x] for x in c_display]\n",
    "            ),\n",
    "            self.number_of_rows,\n",
    "            \n",
    "            #pn.widgets.Tabulator(self.param.filtered_data, page_size=10, pagination=\"remote\"),\n",
    "            self._tabulatorWidget()\n",
    "        )\n",
    "#s = DataExplorer(data=turbines).servable()\n",
    "obj = DataExplorer(data=dffull)\n",
    "#s = obj.servable();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.serve(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(obj.param.values().keys())-set(('columns','data','filtered_data','name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dffull['TimeBeg'].unique())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(obj.filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter1App(Viewer):\n",
    "    dffull = param.DataFrame(doc=\"Stores the master dataframe\")\n",
    "    dfbuilt = param.DataFrame(doc=\"Stores the processed cycle run\")\n",
    "\n",
    "    expname = param.String();\n",
    "    unit = param.String();\n",
    "    run = param.String();\n",
    "\n",
    "    def __init__(self,**params):\n",
    "        # get first info and set as default property\n",
    "        expname,unit,run = list(dffull.groupby(['expname','unit','run']).groups.keys())[0];\n",
    "        #print(expname,unit,run);\n",
    "        self.param.expname.default = expname;\n",
    "        self.param.unit.default = unit;\n",
    "        self.param.run.default = run;\n",
    "    \n",
    "    def __panel__(self):\n",
    "        # return pn.Column(\n",
    "        #     pn.Row(\n",
    "        #         pn.Column(\n",
    "        #             pn.widgets.MultiChoice.from_param(self.param.columns, width=400),\n",
    "        #         ),\n",
    "        #         #pn.Column(self.param.year, self.param.capacity),\n",
    "        #         pn.\n",
    "        #     ),\n",
    "            \n",
    "        #     #pn.widgets.Tabulator(self.param.filtered_data, page_size=10, pagination=\"remote\"),\n",
    "        #     self._tabulatorWidget()\n",
    "\n",
    "        # pn.Column(\n",
    "\n",
    "        # )\n",
    "        print('2 __panel__');\n",
    "        #pn.state.location.sync(obj2,['unit'])\n",
    "        print('2 __panel__',pn.state.location);\n",
    "        return pn.Column(\n",
    "            pn.Row(\n",
    "                self.param.expname,self.param.unit,self.param.run\n",
    "            ),\n",
    "            'PLOT GOES HERE'\n",
    "        );\n",
    "obj2 = Plotter1App(dffull = dffull, dfbuilt = dfbuilt);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel Multi-Page Setup 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:5006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__panel__() method called\n",
      "_tabulatorWidget called\n",
      "2 __panel__\n",
      "2 __panel__ <Location Location03331>\n",
      "2 __panel__\n",
      "2 __panel__ <Location Location03358>\n",
      "2 __panel__\n",
      "2 __panel__ <Location Location03385>\n"
     ]
    }
   ],
   "source": [
    "def page1():\n",
    "    return obj\n",
    "\n",
    "def page2():\n",
    "    #pn.state.location.sync(obj2,['unit']);\n",
    "    return obj2\n",
    "ROUTES = {\n",
    "    \"\": page1,\n",
    "    \"2\": page2\n",
    "}\n",
    "# if pn.state.location:\n",
    "#     pn.state.location.sync(obj2)\n",
    "serve = pn.serve(ROUTES, port=5006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Already stopped",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mserve\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SimonGhionea\\miniconda3\\envs\\naatos_sg\\Lib\\site-packages\\panel\\io\\server.py:351\u001b[0m, in \u001b[0;36mServer.stop\u001b[1;34m(self, wait)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m \u001b[38;5;66;03m# Ignore if the event loop is still running\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39m_admin_context:\n\u001b[0;32m    353\u001b[0m     state\u001b[38;5;241m.\u001b[39m_admin_context\u001b[38;5;241m.\u001b[39mrun_unload_hook()\n",
      "File \u001b[1;32mc:\\Users\\SimonGhionea\\miniconda3\\envs\\naatos_sg\\Lib\\site-packages\\bokeh\\server\\server.py:167\u001b[0m, in \u001b[0;36mBaseServer.stop\u001b[1;34m(self, wait)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstop\u001b[39m(\u001b[38;5;28mself\u001b[39m, wait: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Stop the Bokeh Server.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    This stops and removes all Bokeh Server ``IOLoop`` callbacks, as well\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m \n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopped, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlready stopped\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tornado\u001b[38;5;241m.\u001b[39mstop(wait)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Already stopped"
     ]
    }
   ],
   "source": [
    "serve.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.state.location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mydf.to_excel(r'C:\\temp\\summarytable.xlsx',freeze_panes=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(dfraw.groupby(['expname','unit','run']).groups.keys())[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naatos_sg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
